
> Source : https://eng.uber.com/real-time-exactly-once-ad-event-processing/

## 개요

우버는 최근 새로운 기능을 출시했다. 우버잇츠에서 광고를 제공하는 기능이다.  
새로우 기능을 위해서 광고 경매,입찰,기여,레포트를 위한 시스템이 필요하였다.  
이 글은 우버의 첫 번째 준실시간 exactly-once 이벤트 처리 시스템을 오픈 소스를 사용해서 어떻게 구현하였는지를 설명한다.  

## 문제 정의

각 광고들은 각 유저들에 대한 이벤트가 발생한다 (노출, 클릭 이벤트)  
광고 이벤트 처리 시스템의 주요 책임은 광고 이벤트 처리 flow를 관리하고 필터링하고 집계하고 실제 주문과 연관시키고 이러한 데이터를 분석하기 용이한 포맷으로 저장하는 등의 책임이 필요하다  

시스템이 갖추어야 할 조건은 크게 3개로 정의된다
1. 속도
   * 이 시스템이 처리한 데이터를 입력으로 사용하는 downstream 시스템들은 실시간으로 발생하는 광고 이벤트 결과가 필요하다  
    * 광고 시스템의 고객들은 성과 지표들을 보기 원할 것이다
2. 신뢰성
   * 데이터 정합성 측면에서 시스템은 신뢰가 있어야 한다. 광고 이벤트는 실제로 우버가 지불해야하는 돈으로 직결되기 때문에 만약 광고 이벤트가 유실된다면 우버의 잠재적인 수익 감소로 이어지게 될 것이다
    * 우리 광고 시스템의 고객들에게 정확한 지표를 제공해야한다
3. 정확성
    * 이벤트를 더 많이 처리해서는 안된다. 예를 들어 클릭 이벤트를 두 번 카운팅하게 되버리면 광고주에게 실제보다 더 많은 돈을 요청하게 되버리고 광고의 성과 자체도 잘 못 판단될 수 있다. 따라서 우리 시스템은 정확하게 한 번 이벤트를 처리 할 필요성이 있다
    * 우버는 광고가 제공되는 마켓플레이스이기 때문에 자사 서비스에서 발생하는 이벤트이므로 100%의 정확성이 필요하다
    
## 구조

이러한 3가지 요구사항을 만족하기 위해서 우리는 4개의 주요 오픈소스 기술을 사용하였다  
Apache Flink, Apache Kafka, Apache Pinot, Apache Hive 를 사용한다  

* Apache Flink를 이용한 스트림 처리
    * 준실시간으로 경계선이 없는 스트림 데이터를 처리하는 프레임워크인 Flink를 광고 시스템의 코어 컴포넌트로 사용하고 있다.
    * Apache Flink는 정확하게 한 번 처리를 보장해주거나, 카프카 커넥터를 지원한다거나, window 기반 집계 등을 고려했을 때 광고와 잘 맞다고 판단하여 선택했다
* Apache Kafka를 이용한 메세지 큐
    * 카프카는 우버의 기술 스택의 주춧돌 역할을 하고 있다. 카프카는 정확하게 한 번 처리함을 보장해주고 확장성도 좋다
* Apache Pinot을 이용한 실시간 분석
    * 광고 이벤트 처리 플랫폼의 한 가지 목표는 우리의 고객들에게 성과 분석 정보를 빠르게 제공하는 것이다
    * Pinot은 확장 가능한 분산 OLAP datastore이다. 이는 분석 쿼리에 대한 낮은 지연 속도를 제공해주고 카프카를 통한 준실시간 데이터 수집을 지원하므로 사용했다
* Apache Hive를 이용한 데이터 웨어하우스
    * Apache Hive는 SQL를 이용한 다양한 기능을 통해 거대한 데이터셋을 읽고, 쓰고 관리하는 작업들을 용이하게 해준다.
    * 우버는 카프카를 통ㅎ판 자동 데이터 수집 기능을 가지고 있고 사내 도구들을 이용하여 데이터 사이언티스트와 데이터 분석가들이 Hive를 이용하여 분석이 용이하도록 만들어준다
    
## 고수준의 구조

![1](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2021/09/Figure-1-Ad-Events-Processing-Blog-Diagram.jpeg)

위 그림에서 볼 수 있다시피, 시스템은 3개의 Flink 작업으로 구성되어 있다. 이 작업들은 Kafka 토픽에서 데이터를 읽고 쓰고, 다른 서비스들로부터 데이터를 읽고 쓰는 작업을 하고 있다  
reginal failure를 대비하기 위해 두 개의 레젼 A,B 에 배포되었다. Kafka/Flink의 exactly-once 기능을 사용하여 커밋 된 메세지를 오직 한 번만 읽을 수 있도록 보장해준다.  
Flink 작업에 대해 자세히 들여다보기 이전에 이 시스템이 어떻게 exactly-once 기능을 얻는지 살펴보자

## Exactly-Once

위에서 언급했듯이 우리 시스템의 주요 제약 조건은 정확히 한 번만 이벤트를 처리하는 체계를 구축하는 것이다  
분산 시스템에서 이러한 조건은 어려운 문제 중 하나지만 우리는 노력해서 해결할 수 있었다

1. Flink와 Kafka의 exatcly-once 옵션을 사용하여 모든 메세지가 트랜잭션 방식으로 수행되도록 한다. Flink는 트랜잭션 된 메세지만 읽을 수 있는 'read_committed' 모드가 활성ㅎ퐈된 KafkaConsumer를 사용한다.
2. 모든 레코드(이벤트)에 대해 고유한 식별자를 생성한다. 식별자는 다운스트림 소비자에서 멱등성 및 중복 제거 목적으로 사용된다. 첫 번째 플링크 작업인 Aggregation은 카프카 이벶ㄴ트를 분 단위로 버킷 집계한다. 이는 카프카 메세지의 timestamp를 1분으로 자르고 광고 식별자와 함께 키를 구성하는 요소로 사용된다. 이 단계에서 모든 집계 결과에 대한 UUID를 생성한다. 
   각 window 플링크 작ㄹ업은 체크 포인트가 트리거 될 때까지 집계된 결과를 "커밋되지 않음" 상태로 카프카 싱크에 전송하도록 트리거한다. 다음 체크포인트다 2분마다 트리거되면 메세지는 2단계 커밋 프로토콜을 사용하여 "커밋됨" 상태로 변환된다.
   이렇게 함으로 써 체크포인트에 저장 된 카프카 오프셋과 커밋된 메세지가 항상 일치하게 된다
   카프카 토픽의 소비자들은 커밋된 이벤트만 읽도로 구성되기 때문에 Flink  작업의 실패로인해 발생할 수 있는 커밋되지 않은 모든 이벤트를 무시하게 된다.  
   따라서, Flink가 복구되면 이를 다시 처리하고 새 집계 결과를 생성하고 Kafka에 커밋한 다음 처리를 컨슈머가 사용할 수 있게된다
3. 레코드의 UUID는 ad-budget 서비스에서 멱등성 키로 사용된다. Hive의 경우 중복 제거를 위한 식별자로 사용된다. Pinot에서는 동일한 식별자로 레코드가 복제되지 않도록 upsert해서 저장한다

## Upsert in Pinot

우버의 목표 중 하나는 Pinot의 기존 데이터를 카프카의 변경 로그로 업데이트하고 실시간 분석에서 정확한 결과를 제공하는 것이다.  
예를 들어, 금융 대시보드는 정확한 승차 요금을 바탕으로 총 예약을 보고해야하고, 레스토랑 주인들은 우버잇츠의 가장 최신 배송 상태를 기반으로 주문량을 분석할 수 있어야 한다  
우리가 지금 예기하고 있는 광고 이벤트 처리의 경우, 중복을 감지하고 제거해야만 했다. 이 문제를 해결하기 위해 우버는 Pinot을 사용하여 실시간 수집 프로세스 동안 upsert로 결과를 저장하도록 했다  

## Aggregation job

![2](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2021/09/Figure-2-AggregationJob.jpeg)
Aggregation 작업은 많은 작업을 수행하므로 4가지 구송 요소(데이터 필터, 주문 attribute에 대한 지속성, 집계, UUID 생성)로 구성되어있다

1. 데이터 필터
    * 우리는 카프카 토픽에서 모바일 광고 이벤트에 대한 노출/클릭 이벤트를 읽어오는 것으로부터 시작한다. 우선 Filter 오퍼레이터를 사용하여 이벤트가 특정 필드가 존재하는지 이벤트 시간이 너무 오래됬는지 등을 판단하는 작업을 처리한다
    * Keyby 오퍼레이터를 사용하여 이벤트를 논리적인 그룹으로 파티셔닝한다
    * Map 오퍼레이터를 사용하여 입력 스트림에서 이벤트의 중복성을 제거한다. 플링크의 keyed state를 사용하여 이전에 본 이벤트를 추적할 수 있는 매퍼 기능을 활용한다
2. 주문 attribute에 대한 지속성
    * 이제 clean한 데이터를 Docstore 테이블에 저장한다. Docstore를 선택한 이유는 빠르고,안정적이고 시간을 연속적으롯 선택할 수 있기 떄문이다.
    * 따라서 attribution 윈도우가 존재하는 동안에만 이벤트를 저장할 수 있도록 해준다
3. 집계
    * 집계를 위해서 우선 광고 식별자와 분 시간을 조합으로 이벤트 키를 생성한다. 이는 이벤트가 늦게 도착하더라도 이벤트를 항상 올바른 시간 범위로 집계하기 위함이다.
    * 이벤트를 1분 단위의 윈도우 창에 집어넣는다. 우리가 1분으로 선택한 이유는 집계 결과를 사용하는 다운스트림 서비스들이 수용할 수 있을 만큼 충분히 작다. 그리고 분석을 위한 충분히 작은 세분성이다(DW에서 1분은 1시간,6시간 등으로 롤업될 수 있음)
    동시에 쓰기 작업으로 테이터베이스에 과부하가 걸리지 않을 만큼 충분히 큰 윈도우이기 때문이다
      * 마지막으로 aggregation 기능을 사용하여 윈도우 내의 모든 클릭과 노출을 계산한다. 성능 관점에서 보면 집계 기능은 한 번에 하나의 이벤트만 메모리에 보유하므로 광고 트래픽ㄹ 증가에 따라 확장할 수 있기 때문에 훌륭하 다
4. UUID 생성
    * 집계 결과 중에서 필요한 정보만 포함하는 형식으로 변환하는 작업이 필요하다. 이 과정에서 중복 제거 키로 사용되는 UUID를 생성한다
    * Flink/Kafka에서 정확히 한 번 메세지가 처리된다는 점을 감암하였을 때, Kafka 토픽에서 메세지가 커밋되면 UUI를 이용하여 Hive의 중복 및 Pinot 의 upsert에 사용할 수 있다고 확신할 수 있다
    
## Attribution job

![3](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2021/09/Figure-3-OrderAttributionJob.jpeg)

Attribution 작업은 더 간단하다. 우버잇츠에서 발생한 모든 데이터가 포함 된 카프카 토픽에서 주문 데이터를 수집하고 잘못된 주문 이벤트를 필터링해준다.  
그런 다음 aggregation 작업으로 저장 된 Docstore 테이블에 일치하는 광고 이벤트를 쿼리한다. 일치하는 항목이 있으면 attribute를 지정한다  
그런 다음 이벤트 정보를 더 자세하게 설명하는 외부 서비스를 호출해서 enrich 작업을 해준다.  
그리고, pinot 및 Hive에 대한 멱등성을 위해 레코드에 대한 UUID를 생성해주고 Attributged Orderfs 카프카 토픽에 프로듀스해준다

## Union and Load job

![4](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2021/09/Figure-4-Union-and-Load-Job.jpeg)

마지막 작업은 region A,B의 집계 결과를 통합한 다음 최종 사용자가 쿼리할 수 있도록 데이터를 Pinot 및 Hive에 저장할 수 있도록 카프카 토픽에 전달한다  
Pinot 배포가 Active-Active(2개 레전간에 복제되지 않음)이기 때문에 두 레전의 이벤트를 통합해야한다. 

이제 우리는 간단하게 구조를 살펴보았고 Flink job이 어떻게 exactly once 기능을 제공하는지를 상세하게 확인할 수 있었다.  
이제 우리의 요구조건이 어떻게 만족되었는지를 확인해보자

1. Spped
    * 가장 큰 병목지점은 Flink의 체크포인트 간격이다. exactly-once 제약을 고려하였을 때 이벤트가 처리되기 전에 먼저 체크포인트가 커밋되어야 한다
    * 기본 체크포인트 간격은 10분이지만 우리는 2분으로 설정해서 사용하고 있다. 그래서 이것은 실시간은 아니지만 우리 시스템의 고객이나 내부 시스템이 충분히 감내할 수 있을만큼의 간격이다
2. Reliability
    * 우리는 몇 가지 방식으로 신뢰성을 얻는다. cross-region 복제를 사용하여 데이터 센터 관련 문제의 경우 장애 조치를 취할 수 있다
    * Flink의 체크포인트를 사용하여 처리 중에 문제가 발생하여 중닪판 부분부터 다시 시작할 수 있다
    * 카프카의 retention 3일을 설정하여 최악의 경우 데이터 복구가 가능하도록 해준다
    * 안전성에 대한 가장 큰 문제점은 집계 작업 자체에서 발샏ㅇ한다. 집계 작업이 다운되면 이벤트 처리 지연이 발생하며, 우리 시스템에 의존하는 다른 서비스에 다양한 문제를 발생시킬 수 있다. 이 부분은 아직 해결이 필요한 부분이다.
3. Accuracy
    * Kafka/Flink의 정확히 1번 처리하는 기능과 pinot의 upsert문을 통해서 메세지를 한 번만 처리할 것이라는 확신을 가질 수 있다
    

    