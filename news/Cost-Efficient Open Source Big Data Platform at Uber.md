
> Source : https://eng.uber.com/cost-efficient-big-data-platform/

## 개요

우버의 비즈니스가 확장됨에 따라 우버의 데이터 풀이 기하급수적으로 증가하여 처리 비용이 높아졌다.  
우리는 데이터 플랫폼의 비용을 줄이기 위한 작업을 시작했으며, 이는 플랫폼 효율성, 공급 및 수요의 3가지 주제로 문제를 나뉘었다.  
이 글에서 우리는 데이터 플랫폼의 효율성을 개선하고 비용을 낮추기 위한 우리의 노력에 대해서 말할 것이다

## Big Data File Format Optimizations

우리의 HDFS는 Hive 테이블로 대부분 채워져 있다.  
이러한 테이블은 Parquet, ORC 파일 포맷으로 저장되어 있다.  
두 포맷 모두 블록 기반의 columnar 포맷이다. 즉, 파일은 각 컬럼별로 여러 블럭들로 구성되어있다 (각 블록은 많은 행으로 구성되어 있음 대략 10,000개 씩)  
우리는 HDFS 파일에 대해 상당한 시간을 조사하였고 Parquet 형식에 중점을 두어 최적화를 수행하기로 결정하였다  

1. 압축 알고리즘
   1. 기본적으로 Parquet 내부의 압축 알고리즘으로 GZIP 6레벨을 사용한다. Facebook에서는 최근 ZSTD 압축 방식을 Parquet 포맷에 대해 실험한 적이 있는데 이러한 실험이 우리에게 큰 인상을 남겼다.  
   2. 그들의 실험에서 ZSTD 레벨 9 및 레벨 19는 GZIP 기반 Parquet 파일에 비해 파일 크기를 각각 8%, 12% 줄일 수 있었다. 또한, 압축 해제 속도도 더 빠르다.
   3. 우리는 1개월 후에 데이터를 재압축할 때 ZSTD 레벨 9를, 3개월 후에 ZSTD 레벨 19를 사용하기로 결정했다. ZSTD 레벨 9 압축이 레벨 19보다 3배 빠르기 때문이다.
2. 컬럼 삭제
   1. 많은 Hive 테이블에는 수 많은 열이 포함되어 있으며 그 중 일부는 중첩되어 있다.
   2. 이러한 열을 살펴보면 그 중 일부분은 장기간 보관할 필요가 없다는 것을 알 수 있다.
   3. 열 포맷이 주어졌을 때 열의 압축 해제 및 재압축 없이 파일 내부적으로 열을 삭제하는 것이 가능하다. 이것은 컬럼 삭제를 CPU 효율적인 작업으로 만든다.
   4. 우버에서 이러한 기능을 구현하고 Hive 테이블에 광범위하게 사용하고 있다.
3. 행 정렬
   1. 행 순서는 Parquet 압축 파일 크기에 큰 영향을 줄 수 있다. 이는 Parquet 내부의 Run-Length Encoding 기능과 로컬 반복을 활용하는 압축 알고리즘의 기능 때문이다
   2. 우버에서 가장 큰 Hive 테이블을 대상으로 순서를 수동으로 조정하였을 때 테이블 크기가 50% 이상 줄어들었다
   3. 행을 정렬하는 단순한 방법 중 하나는 로그 테이블에 대한 타임스탬프를 ID별로 지정하는 것이다
   4. 대부분의 로그 테이블은 사용자 ID와 타임스탬프 컬럼이 있기 때문에 이를 통해 컬럼을 매우 잘 압축할 수 있다
4. 델타 인코딩
   1. 타임스태프별로 행을 정렬하게 되면 타임스탬프 간의 차이를 표현하는 크기가 타임스탬프 값 자체를 표현하는 것보다 매우 작기 때문에 Delta Encoding이 데이터 크기를 더 줄일 수 있다고 생각하였다.
   2. 어떤 경우에는 로그가 하트 비트와 같이 일정한 리듬을 가지고 있어서 그 차이가 일정하다
   3. 하지만 Hive, Presto, Spark가 널리 사용되는 환경에서는 [StackOverflow](https://stackoverflow.com/questions/60808914/write-a-parquet-file-with-delta-encoded-coulmns) 질문에 언급된 것처럼 Parquet에 Delta Encoding을 적용하기가 쉽지 않다. 하지만 계속 방법을 모색 중이다.

## HDFS Erasure Coding

Erasure 코딩은 HDFS 파일의 복제 계수를 크게 줄일 수 있다.  
잠재적으로 증가할 수 있는 IOPS 워크로드로 인해 우버에서는 복제 계수가 1.67 및 1.5를 보여주고 있다. (3+2 및 6+3 스키마가 무슨 말..?)  
기본 복제 계수가 3이라는 것을 감안할 때 필요한 디스크 공간을 거의 절반으로 줄일 수 있다

Erasure 코딩을 적용할 수 있는 방법은 다양하다
1. Apache Hadoop 3.0 HDFS Erasure Code
   1. 하둡 3.0에서 공식적으로 구현된 Erasure Code이다. 이 구현의 좋은 점은 크고 작은 파일 모두에서 동작한다는 것이지만 단점은 블록이 Erasure Code에 대해 매두 단편화되기 때문에 IO 효율성이 좋지 않다
2. Client-side Erasure Code
   1. HDFS-RAID 프로젝트에서 페이스북에 의해 처음 구현된 방식이다.
   2. 이 방식의 좋은 점은 매우 IO 효율적이라는 것이고 단점은 작은 파일에는 작동하지 않는다는 것이다.

많은 상의 끝에 우리는 첫 번째 방식인 Apache Hadoop 3.0 HDFS Erasure Code 를 사용하기로 결정했다.
아직은 우리도 테스트 단계에 있지만 이 것을 적용했을 때 HDFS 비용을 줄이는데 큰 영향을 줄 것이라고 확신하고 있다

## YARN Scheduling Policy Improvements

우버에서는 Yarn을 통해서 대부분의 빅데이터 연산을 실행한다.  
다른 대부분의 회사와 마찬가지로 표준 Capacity 스케줄러 방식을 사용했다.  
큐를 계층적 구조로 구성하였으며 MIN 및 MAX 설정을 적용하였다.

이러한 스케줄링 방식을 사용했을 때 처음에는 좋았지만 어느 순간 클러스터 용량 관리에 대한 딜레마를 제공하게 되었다.

1. High Utilization
   1. 우리는 YARN 클러스터의 평균 사용률을 가능한 한 높게 유지하고 싶다
2. Meeting User Expectations
   1. 우리는 클러스터 자원을 사용하는 사용자들에게 그들이 기대하는 리소스 양을 제공하고 싶다

많은 사용자들은 YARN 클러스터에서 예측 가능하지만 스파이크성으로 리소스를 요구하는 작업들을 가지고 있다.  
예를 들면, 하루 중 특정 시간에만 실행되어 비슷한 규모의 리소스와 시간을 소모하는 작업들이 있다.  

만약 우리가 하루종일 피크 리소스 기준으로 MIN 값을 설정해놓으면 하루 중 대부분의 시간동안 실제로 사용되는 리소스는 MIN 보다 낮을 것이니 클러스터 활용률이 낮아지게 된다  
반대로 만약 우리가 피크 리소스 기준으로 MAX 값을 설정해놓으면 리소스는 특정 시간에 MAX에 가깝게 리소스를 사용할 것이며 이는 다른 큐의 잡들에 영향을 끼칠 가능성이 있다  

어떻게 하면 사용자의 리소스 요구사항과 적절한 리소스 배분을 맞출 수 있을까?  
이러한 고민 끝에 우리는 Dynamic MAX 라는 방식을 생각했다.  

Dynamic Max는 다음과 같은 방식으로 구할 수 있다.
`Dynamic_MAX = max(MIN, MIN * 24 – Average_Usage_In_last_23_hours * 23)`  
MIN 값은 큐의 평균 리소스 사용량을 의미한다.  
Dynamic MAX 값은 매 시간마다 새롭게 계산되며, queue의 MAX 값으로 업데이트해준다.

Dynamic Max 에 숨겨진 의도는 다음과 같다
1. 만약 queue가 마지막 23시간 동안 전혀 사용되지 않았다면 우리는 큐가 스파이크를 쳐도 될 만큼의 리소스 양(MIN * 24) 을 허용해준다. 이러한 방식은 스파이크를 치는 상황을 해결해준다.
2. 만약 queue가 마지막 23시간 동안 평균 MIN 만큼의 리소스를 사용했다면 그 다음 시간도 MIN 만큼의 리소스가 할당되도록 할 수 있다. 이러한 방식을 사용함으로 써 24시간 이내 평균 리소스 사용량은 MIN 값을 초과하지 않아 위에서 언급한 남용 사례를 방지할 수 있다.

Dynamic MAX 알고리즘은 사용자들에 설명하기 쉽다. 일반적으로 사용자들의 사용 패턴은 queue의 MIN값의 24배가 필요한 스파이크를 치는 패턴이기 때문이다.  
그러나, 24시간 동안의 누적 사용량은 클러스터의 공정성을 위해 MIN 값의 일정한 사용량보다 많을 수 없다

우리는 일일 사용량 편차의 최대 25%를 설명하기 위해서 MIN을 queue 평균 사용량의 125%로 설정했다.  
이러한 방식은 우리의 YARN 클러스터 사용률을 80% 가까이 올리도록 해주었다.  

## Avoid the Rush Hours

YARN 리소스 사용에서 또 다른 문제점은 클러스터 레벨에서 특정 시간에 리소스 사용량이 많아지는 패턴이 있다는 것이다.  
많은 팀들은 ETL 파이프라인을 새벽 0시~1시 사이에 실행하기를 원한다. 왜냐하면 이전 날의 로그가 준비 된 순간이기 때문이다.  
그러한 파이프라인은 아마 1~2시간 동안 실행될 것이다. 이러한 점은 YARN 클러스터를 해당 1~2시간(rush hours) 매우 바쁘게 만들어준다.

## Cluster of Clusters

우리의 YARN, HDFS 클러스터가 점차 커짐에 따라 우리는 병목 이슈가 발생한다는 것을 발견했다.  
클러스터 규모가 점차 증가함에 따라 HDFS NameNode와 YARN ResourceManager에 부하가 걸려 속도가 느려지기 시작했다  
이는 주로 확장성 문제로 치부되지만 비용 효율성 문제에도 큰 영향을 미친다

이 이슈를 해결하기 위해서 우리에게는 2가지 선택지가 있었다.  
1. 단일 노드의 성능을 끌어올리길 반복한다
   1. 우리는 모니터링을 통해 병목 지점을 찾아서 하나씩 최적화를 할 수 있다
   2. 예를 들면, 우리는 더 많은 CPU 코어와 메모리를 가진 기계를 사용할 수 있다.
2. 클러스터의 클러스터 페더레이션 사용
   1. 우리는 많은 클러스터로 구성된 가상의 클러스터를 생성할 수 있다
   2. 각각의 클러스터는 HDFS와 YARN에 성능 최적화된 크기를 가질 것이다

이러한 선택지에서 우리는 두 번째 방법(페더레이션)을 선택했다.  
그 이유는 다음과 같다

1. 이 세상의 대부분의 HDFS, YARN 클러스터는 우버에서 필요로 하는 규모보다 작다. 만약 우리가 슈퍼 사이즈의 클러스터롤 운영한다면 이러한 선례가 없기 때문에 발견되지 않은 버그들을 마주하게 될 지도 모른다.
2. HDFS 와 YARN의 규모를 우버가 필요한 수준으로 끌어올리기 위해서는 성능과 정교한 기능 사이의 트레이드 오프를 맞추기 위해 소스 코드를 수정해야 할 수도 있다. 예를 들면 하둡의 Capacity 스케줄러에는 태스크 할당 부분의 성능을 저하시키는 복잡한 로직이 있다. 만약에 우리가 그 부분을 소스 코드에서 제거해서 오픈 소스에 적용하려고 해도 그러한 정교한 기능이 다른 회사에게는 필요할 수 있으므로 받아들이지 않을 가능서잉 있다

우리는 오픈소스의 이점을 활용하기 위해서 오픈 소스를 우리가 자체적으로 수정해서 운영하는 방식보다는  
하둡 오픈소스를 최대한 활용하는 방향으로 정했고 그래서 페더레이션을 사용하기로 결정했다  
그리고 하둡 오픈 소스에서 이미 제공하고 있는 Router-Based HDFS, YARN 페더레이션 방식을 사용했다  

## Generalized Load Balancing

1. HDFS DataNode 디스크 활용도 밸런스 문제
   1. 각각의 DataNode들은 서로 다른 디스크 사용 비율을 가지고 있다.
   2. 각 하드디스크는 디스크 공간 활성도에 대한 서로 다른 비율을 가지고 있다
   3. 높은 평균 디스크 공간 활용도를 얻으려면 이 모든 것이 균형을 이룰 필요가 있다
2. YARN NodeManager 활용도 밸런스 문제
   1. 어느 시점에서나 YARN의 각 시스템은 CPU 및 Memory 할당 및 활용 수준이 다를 수 있다
   2. 다시 말하지만, 높은 평균 활용도를 허용하려면 할당과 활용의 균형이 맞춰야 한다

위에서 언급한 유사성은 일반화된 로드 밸런싱 아이디어로 이어지며, 이는 빅데이터 플랫폼 안밖의 더 많은 사용 사례에 적용된다  
마이크로서비스 로드 밸런싱 및 기본 스토리지 로드 밸런싱. 이 모든 것들 사이의 공통 연결 고리는 항상 P99와 평균 사이의 격차를 줄인다는 목표라는 것이다.  

## Query Engines

우리는 우버의 빅데이터 시스템에 다양한 쿼리 엔진을 사용한다 (Hive-on-Spark, Spark, Presto 등)  
이러한 쿼리 엔진들은 여러 파일 포맷(Parquet, ORC)과 조합하여 흥미로운 비용 효율성 매트릭스를 나타낸다  

우리가 쿼리 엔진의 효율성을 높이기 위해 시도한 바는 다음가 같다  
1. Parquet 파일 포멧에 집중
   1. Parquet, ORC 파일 포맷은 행 그룹, 컬럼너 저장소, 블록 레벨, 파일 레벨 전략 등 일반적인 디자인 원칙들을 공유한다.
   2. 하지만, 그들은 완전히 다르게 구현이 되어 있다. 그리고 우버에서 사용하는 다른 시스템과 다른 호환성을 보여준다.  
   3. 우리가 발견한 것은 Parquet 포맷은 스파크에 더 적합하고 ORC 포맷은 Presto에 더 적합하다는 것이다
   4. 더 많은 기능들을 추가해야하는 요구사항이 많아짐에 따라 우리는 이 둘중에 메인 파일 포맷을 선택해야만 했다 그리고 Parquet을 선택했다
   5. 단일 파일 포맷은 우리의 에너지를 낭비되지 않도록 많들어주었다
2. 중첩된 컬럼 pruning
   1. 우버의 빅 데이터 테이블은 놀라울정도로 중첩된 데이터를 가지고 있다.
   2. 그러한 이유는 업스트림 데이터가 JSON 포맷으로 저장되어 있고 Avro 스키마를 활용하고 있기 때문이다
   3. 그 결과, 중첩 된 컬럼을 제거하는 것은 우버의 쿼리 엔진에서 중요한 기능 중 하나가 되었다
   4. 만약 제거하지 안는다면 Parquet 파일에서 중첩된 데이터를 완전히 읽어야 하는 수고를 들여야 한다
   5. 우리는 이러한 기능을 스파크와 프레스토에 모두 추가했다 그리고 둘 모두에서 눈에 띄는 쿼리 성능 향상을 확인할 수 있었다
3. 일반적인 쿼리 패턴 최적화
   1. s


